{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cc3ea95-687b-4bcf-b80e-125990ea60e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 16:05:36.001439: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-10 16:05:36.001522: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-10 16:05:36.001533: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from base64 import b64encode\n",
    "import cv2\n",
    "import glob\n",
    "import h5py\n",
    "import imageio\n",
    "from IPython import get_ipython\n",
    "from IPython.display import HTML, display, clear_output\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "        get_ipython().run_line_magic('autoreload', '2')\n",
    "        get_ipython().run_line_magic('matplotlib', 'qt')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.utils.utils import download_demo, download_model\n",
    "from caiman.source_extraction.volpy import utils\n",
    "from caiman.source_extraction.volpy.volparams import volparams\n",
    "from caiman.source_extraction.volpy.volpy import VOLPY\n",
    "from caiman.source_extraction.volpy.mrcnn import visualize, neurons\n",
    "import caiman.source_extraction.volpy.mrcnn.model as modellib\n",
    "from caiman.summary_images import local_correlations_movie_offline\n",
    "from caiman.summary_images import mean_image\n",
    "from caiman.paths import caiman_datadir\n",
    "\n",
    "logfile = None # Replace with a path if you want to log to a file\n",
    "logger = logging.getLogger('caiman')\n",
    "# Set to logging.INFO if you want much output, potentially much more output\n",
    "logger.setLevel(logging.ERROR)\n",
    "logfmt = logging.Formatter('%(relativeCreated)12d [%(filename)s:%(funcName)20s():%(lineno)s] [%(process)d] %(message)s')\n",
    "if logfile is not None:\n",
    "    handler = logging.FileHandler(logfile)\n",
    "else:\n",
    "    handler = logging.StreamHandler()\n",
    "handler.setFormatter(logfmt)\n",
    "logger.addHandler(handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ff984c3-6259-417d-bc77-d4d61e73e352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Changing key fnames in group data from None to ./test.tif\n",
      "WARNING:root:Changing key fr in group data from None to 400\n",
      "WARNING:root:Changing key max_shifts in group motion from (6, 6) to (5, 5)\n",
      "WARNING:root:Changing key gSig_filt in group motion from None to (3, 3)\n",
      "WARNING:root:Changing key strides in group motion from (96, 96) to (48, 48)\n",
      "WARNING:root:Changing key overlaps in group motion from (32, 32) to (24, 24)\n"
     ]
    }
   ],
   "source": [
    "# File path to movie file (will download if not present)\n",
    "# fnames = './../../../Data/Optosynth/optosynth__1__20__5.tif'\n",
    "fnames = './test.tif'\n",
    "\n",
    "# File path to ROIs file (will download if not present)\n",
    "# path_ROIs = download_demo('demo_voltage_imaging_ROIs.hdf5', 'volpy')  \n",
    "file_dir = os.path.split(fnames)[0]\n",
    "\n",
    "# Setup some parameters for data and motion correction dataset parameters\n",
    "fr = 400                                        # sample rate of the movie\n",
    "ROIs = None                                     # Region of interests\n",
    "index = None                                    # index of neurons\n",
    "weights = None                                  # reuse spatial weights by \n",
    "                                                # opts.change_params(params_dict={'weights':vpy.estimates['weights']})\n",
    "# Motion correction parameters\n",
    "pw_rigid = False                                # flag for pw-rigid motion correction\n",
    "gSig_filt = (3, 3)                              # size of filter, in general gSig (see below),\n",
    "                                                # change this one if algorithm does not work\n",
    "max_shifts = (5, 5)                             # maximum allowed rigid shift\n",
    "strides = (48, 48)                              # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = (24, 24)                             # overlap between patches (size of patch strides+overlaps)\n",
    "max_deviation_rigid = 3                         # maximum deviation allowed for patch with respect to rigid shifts\n",
    "border_nan = 'copy'\n",
    "\n",
    "opts_dict = {\n",
    "    'fnames': fnames,\n",
    "    'fr': fr,\n",
    "    'index': index,\n",
    "    'ROIs': ROIs,\n",
    "    'weights': weights,\n",
    "    'pw_rigid': pw_rigid,\n",
    "    'max_shifts': max_shifts,\n",
    "    'gSig_filt': gSig_filt,\n",
    "    'strides': strides,\n",
    "    'overlaps': overlaps,\n",
    "    'max_deviation_rigid': max_deviation_rigid,\n",
    "    'border_nan': border_nan\n",
    "}\n",
    "\n",
    "opts = volparams(params_dict=opts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b47b0905-f312-4349-a80e-e12c4debb241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a cluster for parallel processing\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='multiprocessing', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "222c1ef1-d291-4252-864f-79d0ec474eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 672 ms, sys: 166 ms, total: 838 ms\n",
      "Wall time: 25.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create a motion correction object with the specified parameters\n",
    "mc = MotionCorrect(fnames, dview=dview, **opts.get_group('motion'))\n",
    "mc.motion_correct(save_movie=True)\n",
    "dview.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cba8ba27-3a3e-4eee-add0-a679410ae498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Changing key fnames in group data from ./test.tif to /home/janwillem/caiman_data/temp/memmap__d1_116_d2_498_d3_1_order_C_frames_7500.mmap\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<caiman.source_extraction.volpy.volparams.volparams at 0x7fcae4bcd6a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='multiprocessing', n_processes=None, single_thread=False)\n",
    "border_to_0 = 0 if mc.border_nan == 'copy' else mc.border_to_0\n",
    "fname_new = cm.save_memmap_join(mc.mmap_file, base_name='memmap_',\n",
    "                           add_to_mov=border_to_0, dview=dview, n_chunks=10)\n",
    "dview.terminate()\n",
    "\n",
    "# Change fnames to the new motion corrected one\n",
    "opts.change_params(params_dict={'fnames': fname_new})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0afc7e8-939c-430d-92ad-d942c9d977f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing cell number 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janwillem/.conda/envs/caiman-env/lib/python3.9/site-packages/caiman/source_extraction/volpy/spikepursuit.py:194: FutureWarning: The parameters `shift_x` and `shift_y` are deprecated since v0.23 and will be removed in v0.26. Use `pad_footprint` or modify the footprintmanually instead.\n",
      "  bwexp = dilation(bw, np.ones([args['context_size'], args['context_size']]), shift_x=True, shift_y=True)\n",
      "WARNING:root:Selecting top 100 spikes for template\n",
      "WARNING:root:Selecting top 100 spikes for template\n",
      "WARNING:root:Selecting top 100 spikes for template\n"
     ]
    }
   ],
   "source": [
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='multiprocessing', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1eafcf6-06b2-4642-90a0-bfa1a932b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROIs = np.zeros((1, 116, 498), dtype='bool')\n",
    "ROIs[0, 25:100, 100:400] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "222e2f36-f217-41f8-8029-6de62254199b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Changing key ROIs in group data from None to [[[False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  ...\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]]]\n",
      "WARNING:root:Changing key index in group data from None to [0]\n"
     ]
    }
   ],
   "source": [
    "#Parameters for trace denoising and spike extraction\n",
    "ROIs = ROIs                                   # region of interests\n",
    "index = list(range(len(ROIs)))                # index of neurons\n",
    "weights = None                                # if None, use ROIs for initialization; to reuse weights check reuse weights block \n",
    "\n",
    "template_size = 0.02                          # half size of the window length for spike templates, default is 20 ms \n",
    "context_size = 35                             # number of pixels surrounding the ROI to censor from the background PCA\n",
    "visualize_ROI = False                         # whether to visualize the region of interest inside the context region\n",
    "flip_signal = True                            # Important!! Flip signal or not, True for Voltron indicator, False for others\n",
    "hp_freq_pb = 1 / 3                            # parameter for high-pass filter to remove photobleaching\n",
    "clip = 100                                    # maximum number of spikes to form spike template\n",
    "threshold_method = 'adaptive_threshold'       # adaptive_threshold or simple \n",
    "min_spikes= 10                                # minimal spikes to be found\n",
    "pnorm = 0.5                                   # a variable deciding the amount of spikes chosen for adaptive threshold method\n",
    "threshold = 3                                 # threshold for finding spikes only used in simple threshold method, Increase the threshold to find less spikes\n",
    "do_plot = False                               # plot detail of spikes, template for the last iteration\n",
    "ridge_bg= 0.01                                # ridge regression regularizer strength for background removement, larger value specifies stronger regularization \n",
    "sub_freq = 20                                 # frequency for subthreshold extraction\n",
    "weight_update = 'ridge'                       # ridge or NMF for weight update\n",
    "n_iter = 2                                    # number of iterations alternating between estimating spike times and spatial filters\n",
    "\n",
    "opts_dict={'fnames': fname_new,\n",
    "            'ROIs': ROIs,\n",
    "            'index': index,\n",
    "            'weights': weights,\n",
    "            'template_size': template_size, \n",
    "            'context_size': context_size,\n",
    "            'visualize_ROI': visualize_ROI, \n",
    "            'flip_signal': flip_signal,\n",
    "            'hp_freq_pb': hp_freq_pb,\n",
    "            'clip': clip,\n",
    "            'threshold_method': threshold_method,\n",
    "            'min_spikes':min_spikes,\n",
    "            'pnorm': pnorm, \n",
    "            'threshold': threshold,\n",
    "            'do_plot':do_plot,\n",
    "            'ridge_bg':ridge_bg,\n",
    "            'sub_freq': sub_freq,\n",
    "            'weight_update': weight_update,\n",
    "            'n_iter': n_iter}\n",
    "\n",
    "opts.change_params(params_dict=opts_dict); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7292e8f0-9d50-4cd5-b9b4-fadffac06da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<caiman.source_extraction.volpy.volpy.VOLPY at 0x7fcae4bc1b20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vpy = VOLPY(n_processes=n_processes, dview=dview, params=opts)\n",
    "vpy.fit(n_processes=n_processes, dview=dview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3badcd7-3456-4e7f-97ea-4ab64b8f1c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    }
   ],
   "source": [
    "print(np.where(vpy.estimates['locality'])[0])    # neurons that pass locality test\n",
    "idx = np.where(vpy.estimates['locality'] > 0)[0]\n",
    "print(idx)# reconstructed movie\n",
    "scope = (0,vpy.estimates['t_sub'].shape[1])\n",
    "\n",
    "vpy.estimates['weights'][vpy.estimates['weights']<0] = 0    \n",
    "A = vpy.estimates['weights'][idx].transpose([1,2,0]).reshape((-1,len(idx)))\n",
    "C = vpy.estimates['t_rec'][idx,scope[0]:scope[1]]\n",
    "mv_rec = np.dot(A, C).reshape((116,498,scope[1]-scope[0])).transpose((2,0,1))    \n",
    "mv_rec = cm.movie(mv_rec,fr=400)\n",
    "mv_rec = (mv_rec - mv_rec.min())/(mv_rec.max()-mv_rec.min())\n",
    "mv_rec.play(fr=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ed9ac9-0a9a-45d1-ab76-3e68850ede40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
